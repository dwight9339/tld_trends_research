{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12186917,"sourceType":"datasetVersion","datasetId":7676098}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Domain Name Trends: Popularity & Pricing of `.io` and Other Alt-TLDs\n\nThis notebook explores the rise of alternative top-level domains (TLDs)‚Äîspecifically `.io`, along with `.ai`, `.co`, `.dev`, and `.app`‚Äîwith a focus on two core questions:\n\n### Research Questions\n\n1. **When did `.io` (and other alt-TLDs) begin to take off in popularity?**  \n   In other words: when did developers, startups, and tech products begin registering them in significant numbers?\n\n2. **How have prices for `.io` domains changed over time?**  \n   Can we detect major shifts in value, spikes in demand, or effects from registry-driven price changes?\n\n---\n\n### Methods & Data Sources\n\nTo answer these questions, we use two main approaches:\n\n#### 1. Certificate Transparency Data via [`crt.sh`](https://crt.sh/)\nEvery public HTTPS-enabled website must issue a certificate. By querying `crt.sh`, a searchable index of Certificate Transparency logs, we can:\n- Estimate when a domain first appeared ‚Äúin the wild‚Äù (first cert issuance)\n- Build a year-by-year timeline of domain adoption per TLD\n\nThis gives us a strong, passive signal of when TLDs gained traction‚Äîespecially in public-facing apps and startups.\n\n#### 2. Domain Sale Price Data (Optional Extension)\nWhere possible, we‚Äôll supplement our analysis with public domain sale data from:\n- NameBio (if available)\n- Historical WHOIS APIs or registrars (if feasible)\n- Public datasets on secondary market sales\n\nThis gives us insight into how perceived value has changed‚Äîparticularly for `.io`, where speculation and hype have played major roles.\n\n---\n\n### Notebook Outputs\n\n- üìà Trendline: first-seen cert dates for top domains, grouped by TLD and year\n- üí∏ (Optional) Timeline of average public sale prices for `.io` and peers\n- üîé Visual cues on inflection points, e.g. post-2014 tech startup boom\n","metadata":{}},{"cell_type":"markdown","source":"# Step 1: Choosing a Set of Domain Names for Each TLD\n\nWe'll start by digging into [Cisco's top 1-Million domains](https://s3-us-west-1.amazonaws.com/umbrella-static/index.html) list to select cohorts of about 1,000 domains for each TLD of interest. We'll aim for a good mix of popular and less popular domains in each.","metadata":{}},{"cell_type":"code","source":"!pip --quiet install tldextract","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T18:04:25.949742Z","iopub.execute_input":"2025-06-16T18:04:25.950773Z","iopub.status.idle":"2025-06-16T18:04:29.757162Z","shell.execute_reply.started":"2025-06-16T18:04:25.950738Z","shell.execute_reply":"2025-06-16T18:04:29.756052Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"### TLDs of interest\nog_tlds = [\"com\", \"net\", \"org\"]\nalt_tlds = [\"io\", \"ai\", \"co\"]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-16T18:16:24.099538Z","iopub.execute_input":"2025-06-16T18:16:24.099836Z","iopub.status.idle":"2025-06-16T18:16:24.105394Z","shell.execute_reply.started":"2025-06-16T18:16:24.099805Z","shell.execute_reply":"2025-06-16T18:16:24.104214Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"import pandas as pd\n\n# Load the dataset\ntop_domains_df = pd.read_csv(\"../input/top-domain-data/cisco-top-1m.csv\", names=[\"rank\", \"domain\"])\n\n# Preview\ntop_domains_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T17:30:09.535147Z","iopub.execute_input":"2025-06-16T17:30:09.535509Z","iopub.status.idle":"2025-06-16T17:30:11.648045Z","shell.execute_reply.started":"2025-06-16T17:30:09.535484Z","shell.execute_reply":"2025-06-16T17:30:11.646910Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   rank              domain\n0     1          google.com\n1     2       microsoft.com\n2     3  data.microsoft.com\n3     4            e2ro.com\n4     5       node.e2ro.com","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank</th>\n      <th>domain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>google.com</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>microsoft.com</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>data.microsoft.com</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>e2ro.com</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>node.e2ro.com</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def get_tld(domain):\n    return domain.split(\".\")[-1]\n\ntop_domains_df[\"tld\"] = top_domains_df[\"domain\"].apply(get_tld)\ntop_domains_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T17:34:32.573809Z","iopub.execute_input":"2025-06-16T17:34:32.574667Z","iopub.status.idle":"2025-06-16T17:34:33.094005Z","shell.execute_reply.started":"2025-06-16T17:34:32.574640Z","shell.execute_reply":"2025-06-16T17:34:33.093227Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   rank              domain  tld\n0     1          google.com  com\n1     2       microsoft.com  com\n2     3  data.microsoft.com  com\n3     4            e2ro.com  com\n4     5       node.e2ro.com  com","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank</th>\n      <th>domain</th>\n      <th>tld</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>google.com</td>\n      <td>com</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>microsoft.com</td>\n      <td>com</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>data.microsoft.com</td>\n      <td>com</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>e2ro.com</td>\n      <td>com</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>node.e2ro.com</td>\n      <td>com</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Print counts for each of our TLDs of interest\nall_tlds = og_tlds + alt_tlds\nfiltered = top_domains_df[top_domains_df[\"tld\"].isin(all_tlds)]\ncounts = filtered[\"tld\"].value_counts().reindex(all_tlds, fill_value=0)\ncounts_df = counts.reset_index()\ncounts_df.columns = [\"TLD\", \"Count\"]\ncounts_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T18:08:55.834368Z","iopub.execute_input":"2025-06-16T18:08:55.834687Z","iopub.status.idle":"2025-06-16T18:08:56.006970Z","shell.execute_reply.started":"2025-06-16T18:08:55.834664Z","shell.execute_reply":"2025-06-16T18:08:56.006066Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"   TLD   Count\n0  com  583019\n1  net  152577\n2  org   27546\n3   io   28358\n4   ai    2821\n5   co    5585\n6  dev    2320","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TLD</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>com</td>\n      <td>583019</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>net</td>\n      <td>152577</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>org</td>\n      <td>27546</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>io</td>\n      <td>28358</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ai</td>\n      <td>2821</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>co</td>\n      <td>5585</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>dev</td>\n      <td>2320</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# We want to filter out all of the infra subdomains \n# to get a clearer picture of how many individual companies\n# are actually using these domains\n\nimport tldextract\n\n# Add eTLD+1 (root domain) column\ntop_domains_df[\"root_domain\"] = top_domains_df[\"domain\"].apply(\n    lambda d: f\"{tldextract.extract(d).domain}.{tldextract.extract(d).suffix}\"\n)\n\n# Define unwanted infrastructure keywords\ninfra_keywords = [\"cdn\", \"ads\", \"akamai\", \"edge\", \"sdk\", \"analytics\", \"api\", \"gateway\", \"internal\", \"tooling\", \"uat\", \"metrics\"]\n\ndef is_infra(domain):\n    return any(kw in domain.lower() for kw in infra_keywords)\n\n# Filter out infrastructure and drop duplicate root domains\nfiltered_top_domains_df = top_domains_df[~top_domains_df[\"domain\"].apply(is_infra)].copy()\nfiltered_top_domains_df = filtered_top_domains_df.drop_duplicates(\"root_domain\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T18:13:18.508638Z","iopub.execute_input":"2025-06-16T18:13:18.509065Z","iopub.status.idle":"2025-06-16T18:13:29.971893Z","shell.execute_reply.started":"2025-06-16T18:13:18.509034Z","shell.execute_reply":"2025-06-16T18:13:29.970550Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Print counts for each TLD after filtering out infra subdomains\nall_tlds = og_tlds + alt_tlds\nfiltered = filtered_top_domains_df[filtered_top_domains_df[\"tld\"].isin(all_tlds)]\ncounts = filtered[\"tld\"].value_counts().reindex(all_tlds, fill_value=0)\ncounts_df = counts.reset_index()\ncounts_df.columns = [\"TLD\", \"Count\"]\ncounts_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T18:17:23.459707Z","iopub.execute_input":"2025-06-16T18:17:23.460062Z","iopub.status.idle":"2025-06-16T18:17:23.526768Z","shell.execute_reply.started":"2025-06-16T18:17:23.460039Z","shell.execute_reply":"2025-06-16T18:17:23.525851Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"   TLD  Count\n0  com  99829\n1  net  11704\n2  org   7862\n3   io   4299\n4   ai    992\n5   co   1828","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TLD</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>com</td>\n      <td>99829</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>net</td>\n      <td>11704</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>org</td>\n      <td>7862</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>io</td>\n      <td>4299</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ai</td>\n      <td>992</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>co</td>\n      <td>1828</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"import random\n\n# Parameters\nnum_samples = counts_df[\"Count\"].min()       # total per TLD\nnum_top = 100           # how many from the top-ranked domains\nnum_random = num_samples - num_top\n\n# Store results\ntop_samples = []\nrandom_samples = []\n\n# Loop through each TLD of interest\nfor tld in all_tlds:\n    tld_df = filtered_top_domains_df[filtered_top_domains_df[\"tld\"] == tld].copy()\n    \n    # Sort by rank (ascending: rank 1 is most popular)\n    tld_df_sorted = tld_df.sort_values(\"rank\")\n    \n    # Grab top N\n    top_n_df = tld_df_sorted.head(num_top)\n    \n    # Random sample from the remaining\n    top_n_df = tld_df_sorted.head(num_top).copy()\n    random_df = remaining_df.sample(n=min(num_random, len(remaining_df)), random_state=42).copy()\n    \n    top_n_df[\"cohort\"] = \"top\"\n    random_df[\"cohort\"] = \"random\"\n\n    \n    # Append to results\n    top_samples.append(top_n_df)\n    random_samples.append(random_df)\n\n# Combine all into one final DataFrame\nfinal_domains = pd.concat(top_samples + random_samples).reset_index(drop=True)\n\n# Preview\nfinal_domains.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T18:18:35.935393Z","iopub.execute_input":"2025-06-16T18:18:35.935684Z","iopub.status.idle":"2025-06-16T18:18:36.150056Z","shell.execute_reply.started":"2025-06-16T18:18:35.935664Z","shell.execute_reply":"2025-06-16T18:18:36.148877Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"   rank             domain  tld        root_domain cohort\n0     1         google.com  com         google.com    top\n1     2      microsoft.com  com      microsoft.com    top\n2     4           e2ro.com  com           e2ro.com    top\n3     7  windowsupdate.com  com  windowsupdate.com    top\n4    10         office.com  com         office.com    top","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank</th>\n      <th>domain</th>\n      <th>tld</th>\n      <th>root_domain</th>\n      <th>cohort</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>google.com</td>\n      <td>com</td>\n      <td>google.com</td>\n      <td>top</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>microsoft.com</td>\n      <td>com</td>\n      <td>microsoft.com</td>\n      <td>top</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>e2ro.com</td>\n      <td>com</td>\n      <td>e2ro.com</td>\n      <td>top</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>windowsupdate.com</td>\n      <td>com</td>\n      <td>windowsupdate.com</td>\n      <td>top</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10</td>\n      <td>office.com</td>\n      <td>com</td>\n      <td>office.com</td>\n      <td>top</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"# Number of domains per TLD to display\nn_per_tld = 10\n\n# Create dictionary: {tld: [list of domains]}\ntld_columns = {\n    tld: final_domains[final_domains[\"tld\"] == tld]\n            .sample(n=min(n_per_tld, len(final_domains[final_domains[\"tld\"] == tld])), random_state=1)\n            .sort_values(\"rank\")[\"domain\"]\n            .tolist()\n    for tld in all_tlds\n}\n\n# Convert to DataFrame, aligning shorter columns\npreview_table = pd.DataFrame.from_dict(tld_columns, orient=\"columns\")\n\n# Display the table\npreview_table\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T18:18:56.815907Z","iopub.execute_input":"2025-06-16T18:18:56.816220Z","iopub.status.idle":"2025-06-16T18:18:56.855196Z","shell.execute_reply.started":"2025-06-16T18:18:56.816194Z","shell.execute_reply":"2025-06-16T18:18:56.854116Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"                   com               net                 org             io  \\\n0          aaplimg.com     bidswitch.net          oneget.org  bidmachine.io   \n1        instagram.com        smaato.net    getgreenshot.org     codepen.io   \n2  app-measurement.com          a-mo.net    collegeboard.org      shopee.io   \n3            3lift.com   ttoverseaus.net           nuget.org        fpjs.io   \n4      amazonalexa.com       cedexis.net     beachapedia.org  anonymised.io   \n5     sharethrough.com       nflximg.net            hltv.org        zprk.io   \n6           inmobi.com         fwmrm.net  sciencecareers.org    bitdrift.io   \n7        appsflyer.com      nintendo.net          adtidy.org     pubeasy.io   \n8            liadm.com  conferdeploy.net             acm.org    airbrake.io   \n9            lijit.com    discordapp.net      sciencemag.org    customer.io   \n\n                ai              co  \n0       powerad.ai   wunderkind.co  \n1   forethought.ai     teramind.co  \n2        go2app.ai    redcanary.co  \n3         lunio.ai    mailmunch.co  \n4     writefull.ai         9lib.co  \n5     ivastudio.ai        invol.co  \n6           afp.ai     squidapp.co  \n7         pushy.ai   pango-paas.co  \n8      superops.ai  smartytouch.co  \n9  prod.yospace.ai         w-mt.co  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>com</th>\n      <th>net</th>\n      <th>org</th>\n      <th>io</th>\n      <th>ai</th>\n      <th>co</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aaplimg.com</td>\n      <td>bidswitch.net</td>\n      <td>oneget.org</td>\n      <td>bidmachine.io</td>\n      <td>powerad.ai</td>\n      <td>wunderkind.co</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>instagram.com</td>\n      <td>smaato.net</td>\n      <td>getgreenshot.org</td>\n      <td>codepen.io</td>\n      <td>forethought.ai</td>\n      <td>teramind.co</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>app-measurement.com</td>\n      <td>a-mo.net</td>\n      <td>collegeboard.org</td>\n      <td>shopee.io</td>\n      <td>go2app.ai</td>\n      <td>redcanary.co</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3lift.com</td>\n      <td>ttoverseaus.net</td>\n      <td>nuget.org</td>\n      <td>fpjs.io</td>\n      <td>lunio.ai</td>\n      <td>mailmunch.co</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>amazonalexa.com</td>\n      <td>cedexis.net</td>\n      <td>beachapedia.org</td>\n      <td>anonymised.io</td>\n      <td>writefull.ai</td>\n      <td>9lib.co</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>sharethrough.com</td>\n      <td>nflximg.net</td>\n      <td>hltv.org</td>\n      <td>zprk.io</td>\n      <td>ivastudio.ai</td>\n      <td>invol.co</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>inmobi.com</td>\n      <td>fwmrm.net</td>\n      <td>sciencecareers.org</td>\n      <td>bitdrift.io</td>\n      <td>afp.ai</td>\n      <td>squidapp.co</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>appsflyer.com</td>\n      <td>nintendo.net</td>\n      <td>adtidy.org</td>\n      <td>pubeasy.io</td>\n      <td>pushy.ai</td>\n      <td>pango-paas.co</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>liadm.com</td>\n      <td>conferdeploy.net</td>\n      <td>acm.org</td>\n      <td>airbrake.io</td>\n      <td>superops.ai</td>\n      <td>smartytouch.co</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>lijit.com</td>\n      <td>discordapp.net</td>\n      <td>sciencemag.org</td>\n      <td>customer.io</td>\n      <td>prod.yospace.ai</td>\n      <td>w-mt.co</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"# Part 2: Searching for Years of First Certificates\n\nWe'll use `crt.sh` to search for the dates from the first certificates issued to each of the domains we've found to approximate how long ago they were registered.","metadata":{}},{"cell_type":"code","source":"import requests\nimport time\nfrom datetime import datetime\n\n# Query for the domain's cert history and extract the date from the earliest one\ndef get_first_cert_year(domain):\n    url = f\"https://crt.sh/?q={domain}&output=json\"\n    try:\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n        data = response.json()\n\n        if not data:\n            return None\n        \n        # Get earliest not_before date\n        cert_dates = [entry.get(\"not_before\") for entry in data if \"not_before\" in entry]\n        cert_dates = [datetime.fromisoformat(d) for d in cert_dates if d]\n        return min(cert_dates).year if cert_dates else None\n\n    except Exception as e:\n        print(f\"[WARN] {domain}: {e}\")\n        return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T18:31:51.714628Z","iopub.execute_input":"2025-06-16T18:31:51.715074Z","iopub.status.idle":"2025-06-16T18:31:51.722298Z","shell.execute_reply.started":"2025-06-16T18:31:51.715047Z","shell.execute_reply":"2025-06-16T18:31:51.721099Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"get_first_cert_year(\"artlist.io\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T18:32:16.814432Z","iopub.execute_input":"2025-06-16T18:32:16.814739Z","iopub.status.idle":"2025-06-16T18:32:24.384852Z","shell.execute_reply.started":"2025-06-16T18:32:16.814715Z","shell.execute_reply":"2025-06-16T18:32:24.383821Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"2014"},"metadata":{}}],"execution_count":41}]}